[
{
	"uri": "nivesh-goyal05.github.io/docs/",
	"title": "  ",
	"tags": null,
	"description": "",
	"content": ""
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/creating_application/workflows/ci_pipelines/",
	"title": "CI Pipeline",
	"tags": null,
	"description": "",
	"content": "Create CI Pipeline    After creating the workflow,click on Add CI Pipeline to add a new CI Pipeline\n   Click on Continous Integration to create a new CI Pipeline\n    Click on Create Pipeline to create the pipeline\n   Key Description     Pipeline Name Name of the pipeline   Source Type Select the source through which CI Pipeline will be triggered.   Branch Name/Tag Regex Enter branch name/tag regex   Pre-build Stages Scripts to be executed before building image   Post-build Stages Scripts to be executed after building image   Advanced Configurations Arguments for CI    Update CI Pipeline You can update all the CI pipeline configurations after the CI pipeline is created except for the pipeline name, if you wish to change that you need to create another CI Pipeline\n   Click on your CI Pipeline, to update the changes to your CI Pipeline.\n   Click on Update Pipeline to update the changes you have made to your CI Pipeline\nDelete CI Pipeline You can delete the CI pipeline, if you don\u0026rsquo;t require the CI pipeline. You can only delete CI Pipeline if you have no CD Pipeline created in your workflow or to delete CI Pipeline you first have to delete CD Pipeline if you have created it.\nTo Delete a CI Pipeline, go to the App Configurations and then click on Workflow editor\n   Click on Delete Pipeline to delete the CD Pipeline\nPre/Post CI Stage Pre-build Stages: These stages are run in sequence before the docker image is built\n    Post-build Stages These stages are run in sequence after the docker image is built\n    Automated Test suite integration in CI step using devtron-ci.yaml User can run the Test case using the Devtron Dashboard or by including the Test cases in devtron.ci.yaml file in the source git repository. For reference, check: https://github.com/kumarnishant/getting-started-nodejs/blob/master/devtron-ci.yaml\nThe test cases given in the script will run before the Test Cases given in the devtron.ci.yaml\n       Field Description     version specify the version of yaml   appliesTo applies the changes to a specified branch   type branch type on which changes are to be applied, it can be BRANCH_FIXED or TAG_PATTERN   value branch name on which changes are to be applied, it can take a value as name of branch (\u0026ldquo;master\u0026rdquo;) or as a regular expression (\u0026quot;%d.%d.%d-rc\u0026quot;)   script script which you want to execute, you can also execute the docker commands here   beforeDockerBuildStages script to run before the docker build step   afterDockerBuildStages script to run after the docker build step   outputLocation location where you want to see the output of report of Test cases    External CI Pipeline You can use Devtron for Deployments on Kubernetes while still using your own CI tool such as Jenkins. External CI feature can be used for such cases where the CI tool is hosted outside Devtron architecture.\n    You can send the \u0026lsquo;Payload script\u0026rsquo; to your CI tool such as Jenkins and Devtron will receive the build image everytime the CI Service is triggered or you can you use the Webhook URL which will build image everytime CI Service is triggered using Devtron Dashboard.\n   Key Description     Pipeline Name Name of the pipeline   Source Type \u0026lsquo;Branch Fixed\u0026rsquo; or \u0026lsquo;Tag Regex\u0026rsquo;   Branch Name Name of the branch    Linked CI Pipeline If one code is shared across multiple applications Linked CI Pipeline can be used, and only one image will be build for multiple applications because if there is only one build, it is not advisable to create multiple CI Pipelines.\n   "
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/creating_application/",
	"title": "Creating Application",
	"tags": null,
	"description": "",
	"content": "Welcome! This is the documentation for Creating Applications\n  Parts of Documentation\nGit Material\nDocker Configuration\nDeployment Template\nWorkflows\nConfig Maps\nSecrets\nEnvironment Overrides\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/use_cases/devtron_genric_charts_to_run_cron_jobs_or_one_time_job/",
	"title": "Devtron Generic Helm Chart To Run Cron Job Or One Time Job",
	"tags": null,
	"description": "",
	"content": "Using Devtron-generic-Helm Chart to run Cron Job or One Time job You can discover over 200 Charts from the Devtron Chart store to perform different tasks such as to deploy a YAML file.\nYou can use Devtron-generic-Helm Chart to run the cron jobs or one time job.\nSelect the Devtron-generic Helm Chart from the Devtron Chart Store.\n    Select the Chart Version and the Chart Value of the Chart.\nAnd, then Click on Deploy\n    Configure Devtron-generic-helm chart\n    Click on Deploy Chart\n   Key Description     App Name Name of the app   Project Name of the Project   Environment Select the Environment in which you want to deploy app   Chart Version Select the Version of the chart   Chart Values Select the Chart Value or Create a Custom Value    In values.yaml, you can specify the YAML file that schedules the cron job for your application.\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/creating_application/git_material/",
	"title": "Git Material",
	"tags": null,
	"description": "",
	"content": "Git material is used to pull the application source code during the CI step. Inside git material when you click on “Add material” you will see three options as shown below:\n  Select Provider\n  Git Repo URL\n  Checkout Path\n   Devtron also supports multiple git repositories in a single deployment. We will discuss this in detail in the multi git option below.\n  1. Select Provider In the provider section, you have to select the git provider of your code repository like- Github, Gitlab, and Bitbucket, etc.You can configure your git provider via global configuration.\n 2. Git Repo URL Inside the git repo URL, you have to provide your code repository’s https URL. For Example- https://github.com/Username/Repo_name.git\n    3. Checkout Path The git checkout path is the directory where your code is pulled or cloned for the repository provided in the previous step.\nThis field is optional in case of a single git repository application and you can leave the path as default. The default value of this field is ./\nBut if you want to go with a multi git approach then you can leave the path as default for one of the repository but for other repositories you have to provide this path. In multi git checkout, this checkout path becomes mandatory for other repositories\n    4. Multi Git: As we discussed, Devtron also supports multiple git repositories in a single application. To add multiple repositories, click on add material again and follow the steps from 1 to 3 again.\nPlease note even though you can add multiple repositories only one image will be created based on the docker file as shown in the docker build config.\n Why do we need MultiGit support-\n Let’s try to understand this with an example. Due to security reasons, you may want to keep sensitive configuration like third party API keys in separate access restricted git repositories and source code in a git repository on which every developer has access. To deploy this application both repositories code is required and multi-git will help you to do that.\nProvide a different checkout path for both the repositories, if different repositories are provided the same checkout path then files from different repositories can overwrite each other. These checkout paths will be used by the docker file to create a docker image.\nIf any change is pushed to the configured repositories then the CI will be triggered and the image file will be built based on the latest commits of the configured repositories and pushed to the docker registry.\nFew other examples, where you may want to have multiple repositories for your application and will need multi git checkout support\n  To make code modularize, you are keeping front-end and back-end code in different repositories.\n  Due to security reasons you are keeping configuration files in different access restricted git repositories.\n  Common Library extracted out in different repo so that it can be used via multiple other projects.\n  "
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/global_configurations/manage_notification/",
	"title": "Manage Notification",
	"tags": null,
	"description": "",
	"content": "Notification This feature helps you manage the notifications for your build and deployment pipelines. You can recieve the notifications on Slack or via e-mail.\nClick on Global Configurations-\u0026gt; Notification\nManage Configuration Click on Configurations to manage SES Configurations or Slack Configurations\n    Manage SES Configurations You can manage the SES configuration to recieve e-mails by entering the valid credentials. Make sure your e-mail is verified by SES.\n   Click on Add and configure SES.\n       Key Description     Configuation Name Name of the SES Configuration   Access Key ID Valid AWS Access Key ID   Secret Access Key Valid AWS Secret Access Key   AWS Region Select the AWS Region from the drop-down menu   E-mail Enter the SES verified e-mail id on which you wish to recieve e-mail notifications     Manage Slack Configurations You can manage the Slack configurations to recieve notifications on your preferred Slack channel.\n   Click on Add to add new Slack Channel.\n       Key Description     Slack Channel Name of the Slack channel on which you wish to recieve notifications.   Webhook URL Enter the valid Webhook URL link   Project Select the project name to control user access     Manage Notifications Click on Add New to recieve new notification.\n    Manage Slack Notifications     Send To\nFirst, enter the name of your Slack Channel if you have already configured Slack Channel. If you have not yet configured the Slack Channel, Click on Configure Slack Channel\nSelect Pipelines\n  Then, to fetch pipelines of an application, project and environment.\n  Choose a filter type(environment, project or application)\n  Then you will see a list of pipelines, you can select any number of pipelines. For each pipeline there are 3 types of events Trigger, Success and Failure. Click on the check boxes for the events, you wish to recieve notifications.\n       Click on Save after you have configured Slack notifications.\nManage SES Notifications     Send To\n First, enter the e-mail address/addresses on which you want to send e-mail notifications. Make sure e-mail id\u0026rsquo;s are SES Verified.  If you have not yet configured SES, Click on Configure SES\nSelect Pipelines\n  Then, to fetch pipelines of an application, project and environment.\n  Choose a filter type(environment, project or application)\n  Then you will see a list of pipelines, you can select any number of pipelines. For each pipeline there are 3 types of events Trigger, Success and Failure. Click on the check boxes for the events, you wish to recieve notifications.\n       Click on Save after you have configured the e-mail notification.\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/deploy_chart/overview/",
	"title": "Overview Of Charts",
	"tags": null,
	"description": "",
	"content": "Deploying Charts Charts can be deployed individually or by creating a group of Charts.\nBoth methods are mentioned in the given document.\nDeploying Chart     Select Discover and then select the chart that you want to use\nClick on README.MD to get more idea about the configurations of the chart\n  Select the Chart Version that you want to use and Chart Value, you can either use the default Values or custom values. To know about Custom Values, Click On: Custom Values\nThe configuration values can be edited in the section given below Chart Version.\n   Key Description     App Name The name of the app   Project Project of the app   Environment Environment of the app to be deployed   Chart Version Version of the chart to be used        ReadMe.md present on the left can be used by the user to set configuration values\n   Click on Deploy Chart to deploy the chart\n    You can see the status of the chart deployed. Click on Values.Yaml to reconfigure the deployment.\n    Configuration values can be edited over here by the help of ReadMe.md\nSelect Update And Deploy to update new settings.\nCustom Values You can use the default values or create Custom value by clicking on  Create Custom\n    You can name your Custom Value, select the Chart Version and change the configurations in YAML file.\n    Click on Save Template to save the configurations.\nDeploying Chart Groups To deploy multiple applications and work with them simulataneously, you can use Chart Groups.\nTo create Chart Groups Click on Discover and Click on Create Group\n    Add the Group Name and Description and Click on Create Group\n    You can select the Charts that you want to add in your Chart Group by clicking on \u0026lsquo;+\u0026rsquo; sign. You can select a particular chart multiple number of times according to your requirements.\n   Select the Version and Values for your charts.\nYou can use Default Values or the Custom Values, just make sure the Value that you select for your Chart is comptabile with the Version of the Chart that you are using.\n    To edit the Chart Configuration, Click on \u0026lsquo;Edit\u0026rsquo;\n    You can Add more Charts to your existing Chart Group or Delete Charts from your existing Chart Group.\nAfter making changes, Click on Save to save changes to your Chart Group.\n    If you wish to edit the Chart Configuration, Double Click on that Chart and edit the Configurations in YAML File.\n    You can edit the App Name, Chart Version, Values, Deploy Environment and the YAML file.\n    Key Description     App Name Name of the app   Project Name of Project in which app has to be created   Environment Name of the Environment in which app has to be deployed   Chart Version Select the Version of the chart to be used    Click on Deploy to initiate the deployment of a Chart in Chart Group.\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/",
	"title": "Reference",
	"tags": null,
	"description": "",
	"content": ""
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/deploying_applications/triggering_ci/",
	"title": "Triggering CI",
	"tags": null,
	"description": "",
	"content": "Triggering CI Pipelines     The CI Pipeline can be triggered by selecting Select Material\nCI Pipelines that are set as Automatic are always triggered as soon as a new commit is made to the git branch they\u0026rsquo;re sensing. However, CI Pipelines can always be manually triggered as and if required.\n    Various commits done in the repository can be seen, here along with details like Author, Date etc. Select the commit that you want to trigger and then select \u0026ldquo;Start Build\u0026rdquo; to trigger the CI Pipeline.\nRefresh icon, refreshes Git Commits in the CI Pipeline and fetches the latest commits from the “Repository”\nIgnore Cache : This option will ignore the previous build cache and create a fresh build. If selected, will take a longer build time than usual.\n    It can be seen that the pipeline is triggered here and is the Running state.\nClick on your CI Pipeline or Click on Build History to get the details about the CI Pipeline such as logs, reports etc.\n    You can read the logs of the CI Pipeline from here.\n    Click on Source code to view the details such as commit id, Author and commit message of the Git Material that you have selected for the build.\n   Click on Artifacts to download the reports of the Pre-CI and Post-CI stages if any.\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/creating_application/workflows/cd_pipelines/",
	"title": "CD Pipeline",
	"tags": null,
	"description": "",
	"content": "Create CD Pipeline    Click on \u0026ldquo;+\u0026rdquo; on CI Pipeline to attach a CD Pipeline\n   Select Deploy to Environment to create CD Pipeline\n        Key Description     Pipeline Name Enter the name of the pipeline to be created   Environment Select the environment   Deployment Strategy Select the type of deployment strategy that you want to enable by clicking \u0026ldquo;Add Deployment Strategy\u0026rdquo;    Click on Create Pipeline to create the CD Pipeline\n   The CD Pipeline is created\nUpdate CD Pipeline You can update the CD Pipeline, updatations such as adding Deployment Stage, Deployment Strategy but you cannot update the name of CD Pipeline or it\u0026rsquo;s Deploy Environment, if you require to change such configurations you need to make another CD Pipeline\nTo Update a CD Pipeline, go to the App Configurations and then click on Workflow editor\n    Click on your CD Pipeline to Update/Delete the CD Pipeline\n   Click on Update Pipeline to update the CD Pipeline\nDelete CD Pipeline If you no longer require the CD Pipeline, you can also Delete the Pipeline.\nTo Delete a CD Pipeline, go to the App Configurations and then click on Workflow editor\n   Click on Delete Pipeline to delete the CD Pipeline\nPre/Post CD Stage Pre-deployment Stage Configure actions like db migration, that you want to run before the deployment.\n    Execute in application Environment: If checked, the pre-cd / post-cd pods are created in the deployment cluster otherwise they\u0026rsquo;re created in the devtron build cluster, running in Deployment cluster is recommended if your scripts interact with the cluster services which are not publically exposed\nPost-deployment Stage Configure actions like jira ticket close,that you want to run after the deployment.\n    Execute in application Environment: If checked, the pre-cd / post-cd pods are created in the deployment cluster otherwise they\u0026rsquo;re created in the devtron build cluster, running in Deployment cluster is recommended if your scripts interact with the cluster services which are not publically exposed\nDeployment Strategies A deployment strategy is a way to make changes to an application, without downtime in a way that the user barely notices the changes. There are different types of deployment strategies like Blue/Green Strategy, Rolling Strategy, Canary Strategy, Recreate Strategy. These deployment configuration-based strategies are discussed in this section. Blue Green Stategy Blue-green deployments involve running two versions of an application at the same time and moving traffic from the in-production version (the green version) to the newer version (the blue version).\nblueGreen: autoPromotionSeconds: 30 scaleDownDelaySeconds: 30 previewReplicaCount: 1 autoPromotionEnabled: false    Key Description     autoPromotionSeconds It will make the rollout automatically promote the new ReplicaSet to active Service after this time has passed   scaleDownDelaySeconds It is used to delay scaling down the old ReplicaSet after the active Service is switched to the new ReplicaSet.   previewReplicaCount It will indicate the number of replicas that the new version of an application should run   autoPromotionEnabled It will make the rollout automatically promote the new ReplicaSet to the active service.    Rolling Strategy A rolling deployment slowly replaces instances of the previous version of an application with instances of the new version of the application. Rolling deployment typically waits for new pods to become ready via a readiness check before scaling down the old components. If a significant issue occurs, the rolling deployment can be aborted.\nrolling: maxSurge: \u0026#34;25%\u0026#34; maxUnavailable: 1    Key Description     maxSurge No. of replicas allowed above the scheduled qauntity.   maxUnavailable Maximum number of pods allowed to be unavailable.    Canary Strategy Canary deployments are a pattern for rolling out releases to a subset of users or servers. The idea is to first deploy the change to a small subset of servers, test it, and then roll the change out to the rest of the servers. The canary deployment serves as an early warning indicator with less impact on downtime: if the canary deployment fails, the rest of the servers aren\u0026rsquo;t impacted.\ncanary: maxSurge: \u0026#34;25%\u0026#34; maxUnavailable: 1 steps: - setWeight: 25 - pause: duration: 15 # 1 min - setWeight: 50 - pause: duration: 15 # 1 min - setWeight: 75 - pause: duration: 15 # 1 min    Key Description     maxSurge It defines the maximum number of replicas the rollout can create to move to the correct ratio set by the last setWeight   maxUnavailable The maximum number of pods that can be unavailable during the update   setWeight It is the required percent of pods to move to next step   duration It is used to set the duration to wait to move to the next step.    Recreate The recreate strategy is a dummy deployment which consists of shutting down version A then deploying version B after version A is turned off. A recreate deployment incurs downtime because, for a brief period, no instances of your application are running. However, your old code and new code do not run at the same time.\nrecreate: It terminate the old version and release the new one.\nDoes your app has different requirements in different Environments? Also read Environment Overrides\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/cloning_applications/",
	"title": "Cloning Application",
	"tags": null,
	"description": "",
	"content": "   Select Add New App to Create a new app.\n       Key Description     App Name Name of the new app you want to Create   Project Project name   Template Select the App whose template you want to use to the Create new app    Click on Duplicate App to create App with a template of the Application you have selected from the Drop-down.\n    New application with a duplicate template is created.\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/use_cases/connect_spring_boot_with_mysql_database/",
	"title": "Connect SpringBoot with Mysql Database",
	"tags": null,
	"description": "",
	"content": "Introduction This document will help you to deploy a sample Spring Boot Application, using mysql Helm Chart\n1. Deploy a mysql Helm Chart To deploy mysql Helm Chart, you can refer to our documentation on Deploy mysql Helm Chart\n2. Fork the Git Repository For this example, we are using the following GitHub Repo, you can clone this repository and make following changes in the files.\n* Configure application.properties Set the database configuration in this file.\nspring.datasource.url=jdbc:mysql://\u0026lt;service-name\u0026gt;/\u0026lt;mysql database-name\u0026gt; spring.jpa.hibernate.ddl-auto=update spring.jpa.show-sql=true spring.datasource.username=\u0026lt;mysql-user\u0026gt; spring.datasource.password=\u0026lt;mysql-password\u0026gt; spring.datasource.driver-class-name=com.mysql.jdbc.Driver spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.MySQL5Dialect spring.jpa.open-in-view=true * Configure the Dockerfile # syntax=docker/dockerfile:experimental FROM maven:3.5-jdk-8-alpine as build WORKDIR /workspace/app COPY pom.xml . RUN mvn -B -e -C -T 1C org.apache.maven.plugins:maven-dependency-plugin:3.0.2:go-offline COPY . . RUN mvn clean package -Dmaven.test.skip=true FROM openjdk:8-jdk-alpine RUN addgroup -S demo \u0026amp;\u0026amp; adduser -S demo -G demo VOLUME /tmp USER demo ARG DEPENDENCY=/workspace/app/target/dependency COPY --from=build /workspace/app/target/docker-demo-0.0.1-SNAPSHOT.jar app.jar ENTRYPOINT [\u0026#34;java\u0026#34;,\u0026#34;-jar\u0026#34;, \u0026#34;app.jar\u0026#34;]  3. Create Application on Devtron To learn how to create an application on Devtron, refer to our documentation on Creating Application\n* Git Material In this example, we are using the url of the forked Git Repository.\n* Docker configuration Give, the path of the Dockerfile.\n* Configure Deployment Template Enable Ingress, and give the path on which you want to host the application.\n  * Set up the CI/CD Pipelines Set up the CI/CD pipelines. You can set them to trigger automatically or manually.\n* Trigger Pipelines Trigger the CI Pipeline, build should be Successful. Then trigger the CD Pipeline, deployment pipeline will be initiated, after some time the status should be Healthy.\n4. Final Step * Test Rest API It exposes 3 REST endpoints for it\u0026rsquo;s users to create, to view specific student record and view all student records.\nTo test Rest API, you can use curl command line tool\nCreate a new Student Record\nCreate a new POST request to create a new Transaction. Once the transaction is successfully created, you will get the student id as a response.\nCurl Request is as follows:\nsudo curl -d \u0026#39;{\u0026#34;name\u0026#34;: \u0026#34;Anushka\u0026#34;, \u0026#34;marks\u0026#34;: 98}\u0026#39; -H \u0026#34;Content-Type: application/json\u0026#34; -X POST http://\u0026lt;hostname\u0026gt;/\u0026lt;path-name\u0026gt;/create View All Student\u0026rsquo;s Data\nTo view all student records, GET Request is:\n path will be the one that you have given in Step 3 while configuring the Deployment Template.\nhttp://\u0026lt;hostname\u0026gt;/\u0026lt;path\u0026gt;/viewAll\n    View student\u0026rsquo;s data By student ID\nTo view student data by student id, GET Request is:\nhttp://\u0026lt;hostname\u0026gt;/\u0026lt;path\u0026gt;/view/\u0026lt;id\u0026gt;\npath will be the one that you have given in Step 3 while configuring the Deployment Template.\n   "
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/creating_application/docker_configuration/",
	"title": "Docker Build Configuration",
	"tags": null,
	"description": "",
	"content": "In the previous step, we discussed git configurations. In this section, we will provide information on the docker build config.\nDocker build configuration is used to create and push docker images in the docker registry for your application. You will provide docker related information to build and push docker images in this step.\nOnly one docker image can be created even for multi-git repository application as explained in the previous step.\n  Here you can see, 5 options are present to configure your docker build.\n  Repository\n  Docker file path\n  Docker Registry\n  Docker Repository\n  Docker build arguments\n  Key\n  Value\n       Options Description     Repository Provide the checkout path of the repository in this column, which you had defined earlier in git configuration details   Docker File Path Provide a relative path for your docker file. Dockerfile should be present on this path.   Docker Registry Select the docker registry you wish to use, which will be used to store docker images.   Docker Repository Name of your docker repository that will store a collection of related images. Every image is stored with a new tag version.   Key-value The key parameter and the value for a given key for your docker build. This is Optional. (this can be overridden at CI step later)    1. Repository Provide the checkout path of the repository in this column, which you defined earlier in git configuration details. In the case of multi-git, select the checkout path configured for the repository containing Dockerfile to be used for image creation.\n2. Docker file path Inside the Docker file path option, provide a relative path for your docker file. The default docker file name is Dockerfile but if you are using a custom name for your Dockerfile like xyz_dockerfile, then you have to provide that custom name.\nIf your docker file is not at the root of the repository, then it should contain a relative path to this file. The path will be searched inside the checkout path selected in the previous step.\n3. Docker Registry Select the docker registry you want to use to store docker images. You can have ECR (Elastic Container Registry), DockerHub, etc, and many other registries as your docker registry.\nAdding a registry in the drop-down is configurable. To get a drop-down of these registries into the docker registry option, you have to add the configuration and credentials in the Global Configuration.\n4. Docker Repository You have to provide the docker Registry(ECR) bucket name under the Docker Repository option, but this is optional. If you provide the name of your repository we will use that name but if you don’t provide a name then the docker repository is automatically created and used.\n5. Docker build arguments Many times you use some arguments when you build your Dockerfile. Here you can provide those arguments in key-value format. You can provide one or more arguments and these arguments are optional. Read about the docker command line and arguments.\nOnce all the configuration is done, click on Save Configuration to save the Docker Build Configuration.\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/deploy_chart/examples/",
	"title": "Examples",
	"tags": null,
	"description": "",
	"content": "This Documentation guides you to Deploy different Helm Charts available on Devtron.\nParts of Documentation\nDeploying mySQL Helm Chart Deploying mongoDB Helm Chart\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/deploying_applications/triggering_cd/",
	"title": "Triggering CD",
	"tags": null,
	"description": "",
	"content": "Triggering CD Pipelines     After CI Pipeline is complete, CD Pipeline can be triggered by Clicking on Select Image.\n    Select an image to deploy and then Click on Deploy to trigger the CD Pipeline.\nThe running images are tagged as Running\n    The status of the current deployment can be viewed by Clicking on App Details that will show the Progressing state for 1-2 minutes and then gradually shows Healthy state or Hibernating state, based on the deployment strategy.\nHere, triggering CD Pipeline is successful and the deployment is in \u0026ldquo;Healthy\u0026rdquo; state.\nTo further diagnose deployments, Click here\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/global_configurations/user_access/",
	"title": "User Access",
	"tags": null,
	"description": "",
	"content": "User/Group Authorization     Authorization is used to determine what functions, data, or other parts of an application the user or the group has the access to.\nYou can manage the User and Group access to Projects, Applications, Chart Groups, Environments, and Roles using the User Access feature.\nView Access Levels/Role\nThere are four different view access levels/Role available for both User and Group, namely:\n  View Only : User(s)/Group(s) can view only selected applications.\n  Build and Deploy : User(s)/Group(s) can build and deploy applications on selected environments.\n  Admin : User(s)/Group(s) can view trigger and edit selected applications.\n  Manager : User(s)/Group(s) can view, trigger and edit selected applications, can also manage user access.\n  To control the access of User and Group,\nGo to the left main panel -\u0026gt; Select Global Configurations -\u0026gt; Select User Access\nUsers 1. Add new user Click on Add New User, to add one or multiple users.\n    2. Create User Permissions If you do not wish to give the users super admin permissions, then control their access in Direct Permissions section. Manage the project, Environment, Application and Role access given to the users.\n    You can add multiple rows, for Direct Permissions.\nOnce you have finished assigning the appropriate permissions for the listed users, Click on Save.\n3. Edit User Permissions You can edit the user permissions, by clicking on the downward arrow.\n    You can then edit the user permissions here.\n    After you have done editing the user permissions. Click on Save.\nIf you want to delete the user/users with particular permissions. Click on Delete.\n4. Manage Chart Group Permissions You can also manage the access of users to Chart Groups in your project.\nYou can either give the users permission to Create or Edit.\nClick on the check box of Create, if you want users to create, view, edit or delete chart groups.\n    Click on the checkbox of Edit, if you want to allow or deny users to edit the chart groups.\nSelect on Deny option from the drop-down menu, if you want to restrict the users to edit the chart groups.\n    Select Specific Charts option from the drop-down menu, and then select the chart groups for which you want to allow users to edit, from the other drop-down menu.\n    Once you have configured all the required permissions for the users, Click on Save.\nGroups The advantage of the groups is to define a set of privileges like create, edit or delete for the given set of resources that can be shared among the users within the group. Users can be added to an existing group to utilize the privileges that it grants.\n1. Add new Group Click on Add Group, to create a new group.\n    Enter the Group Name and Description.\n    2. Create Group Permissions Once you have given the group name and group description.\nThen, control the access permissions of groups in Direct Permissionssection. Manage the project, Environment, Application and Role access given to the groups.\n    You can add multiple rows, for Direct Permissions section.\nOnce you have finished assigning the appropriate permissions for the listed users, Click on Save.\n3. Edit Group Permissions You can edit the group permissions, by clicking on the downward arrow.\n    You can then edit the user permissions here.\n    After you have done editing the group permissions. Click on Save.\nIf you want to delete the groups with particular permissions. Click on Delete.\n4. Manage Chart Group Permissions The chart group permissions for the group will be managed in the same way as for the users. For reference, check Manage chart group permissions for users\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/use_cases/connect_expressjs_with_mongodb_database/",
	"title": "Connect Expressjs With Mongodb Database",
	"tags": null,
	"description": "",
	"content": "Introduction In this application, you will learn about how to create a Expressjs Application that connects to mongoDb.\nFollow the below mentioned steps, to deploy the application on Devtron using mongoDb Helm Chart.\n1. Deploy mongoDb Helm Chart To deploy mongoDb Helm Chart, you can refer to our documentation on Deploy mongoDb Helm Chart\n2. Fork the Git Repository For this example, we are using the following GitHub Repo, you can clone this repository and make following changes in the files.\n* Dockerfile This is the Dockerfile. This exposes our expressjs application to port number 8080\n FROM node:7 WORKDIR /app COPY package.json /app RUN npm install COPY . /app CMD node server.js EXPOSE 8080 * db.js File This file will be used to connect to our database. This will include the service-name of the mongoDb Helm Chart, that you have deployed in Step1.\nThe syntax is as follows:\n\u0026lt;service-name\u0026gt;:27017/\u0026lt;database-name\u0026gt;\nThis maps our service name to mongoDb\u0026rsquo;s port number 27017.\n module.exports = { DB: \u0026#39;mondo-dev-mongodb-replicaset-client:27017/sale\u0026#39; }  3. Create Application on Devtron To learn how to create an application on Devtron, refer to our documentation on Creating Application\n* Git Material In this example, we are using the url of the forked Git Repository.\n* Docker configuration Give, the path of the Dockerfile.\n* Configure Deployment Template Enable Ingress, and give the path on which you want to host the application.\n  * Set up the CI/CD Pipelines Set up the CI/CD pipelines. You can set them to trigger automatically or manually.\n* Trigger Pipelines Trigger the CI Pipeline, build should be Successful, then trigger the CD Pipeline, deployment pipeline will be initiated, after some time the status should be Healthy\n4. Final Step Check the Expressjs app connected to mongodb database, running successfully by hitting your application url.\nThe syntax is: http://\u0026lt;hostname\u0026gt;/\u0026lt;path\u0026gt;/\npath will be the one that you have given in Step 3 while configuring the Deployment Template.\nThe output of our application would be as follows:\n  You can see that we are getting the JSON response. We have successfully connected our expressjs application to the mongoDb database.\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/deploying_applications/",
	"title": "Deploying Application",
	"tags": null,
	"description": "",
	"content": "Welcome! This is the documentation for Deploying Applications\nParts of Documentation\nTriggering CI Triggering CD\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/deploy_chart/examples/deploying_mysql_helm_chart/",
	"title": "Deploying Mysql Helm Chart",
	"tags": null,
	"description": "",
	"content": "Introduction stable/mysql Helm chart bootstraps a single node MySQL deployment on a Kubernetes cluster using the Helm package manager.\n    1. Discover the chart from the Chart Store Select the Charts section from the left pane, you will be landed to the Chart Store page. Click on Discover and find stable/mongodb-replicaset Helm Chart.\n    2. Configure the Chart After selecting the stable/mySQL Helm chart, click on Deploy\nEnter the following details, to deploy mysql chart:\n   Key Description     App Name Name of the Chart   Project Select the name of your Project in which you want to deploy the chart   Environment Select the environment in which you want to deploy the chart   Chart Version Select the latest Chart Version   Chart Value Select the latest default value or create a custom value     Configure values.yaml Set the following parameters in the chart, to be later used to connect mysql with your Django Application.\n       Parameters Description     mysqlRootPassword Password for the root user. Ignored if existing secret is provided   mysqlDatabase Name of your mysql database   mysqluser Username of new user to create   mysqlPassword Password for the new user. Ignored if existing secret is provided        Click on Deploy to deploy the Chart\n3. Check the Status of Deployment After clicking on Deploy you will land on a page, that shows the Status of the deployment of the Chart.\nThe Status of the chart should be Healthy. It might take few seconds after initiating the deployment of the chart.\n    In case the Status, of the deployment is Degraded or takes a long time to get deployed.\nClick on the Status or check the logs of the pods to debug the issue.\n4. Extract the Service Name Copy the service name, it will be used to connect your application to mySQL.\n    "
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/creating_application/deployment_template/",
	"title": "Deployment Template",
	"tags": null,
	"description": "",
	"content": "Deployment configuration is the Manifest for the application, it defines the runtime behavior of the application. You can define application behavior by providing information in three sections:\n  Chart Version\n  Yaml file\n  Show application metrics\n    1. Chart version    Key Descriptions     Chart Version Select the Chart Version using which you want to deploy the application.    Devtron uses helm charts for the deployments. And we are having multiple chart versions based on features it is supporting with every chart version.\nOne can see multiple chart version options available in the drop-down. you can select any chart version as per your requirements. By default, the latest version of the helm chart is selected in the chart version option.\nEvery chart version has its own YAML file. Helm charts are used to provide specifications for your application. To make it easy to use, we have created templates for the YAML file and have added some variables inside the YAML. You can provide or change the values of these variables as per your requirement.\nIf you want to see Application Metrics (For example Status codes 2xx, 3xx, 5xx; throughput, and latency) for your application, then you need to select the latest chart version.\nApplication Metrics is not supported for Chart version older than 3.7 version.\n2. Yaml file Container This defines ports on which application services will be exposed to other services\nContainerPort: name: app port: 8080 servicePort: 80    Key Description     name name of the container   port port for the container   servicePort service port for the container    Liveness Probe If this check fails, kubernetes restarts the pod. This should return error code in case of non-recoverable error\nLivenessProbe: Path: \u0026#34;\u0026#34; port: 8080 initialDelaySeconds: 20 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 5 failureThreshold: 3     Key Description     Path It define the path where the liveness needs to be checked.   failureThreshold It defines the maximum number of failures that are acceptable before a given container is not considered as live.   initialDelaySeconds It defines the time to wait before a given container is checked for liveliness.   periodSeconds It defines the time to check a given container for liveness.   successThreshold It defines the number of successes required before a given container is said to fulfil the liveness probe.   timeoutSeconds It defines the time for checking timeout.    Readiness Probe If this check fails, kubernetes stops sending traffic to the application. This should return error code in case of errors which can be recovered from if traffic is stopped\nReadinessProbe: Path: \u0026#34;\u0026#34; port: 8080 initialDelaySeconds: 20 periodSeconds: 10 successThreshold: 1 timeoutSeconds: 5 failureThreshold: 3    Key Description     Path It define the path where the rediness needs to be checked.   failureThreshold It defines the maximum number of failures that are acceptable before a given container is not considered as ready.   initialDelaySeconds It defines the time to wait before a given container is checked for readiness.   periodSeconds It defines the time to check a given container for readiness.   successThreshold It defines the number of successes required before a given container is said to fulfil the rediness probe.   timeoutSeconds It defines the time for checking timeout.    Autoscaling This is connected to HPA and controls scaling up and down in response to request load\nautoscaling: enabled: false MinReplicas: 1 MaxReplicas: 2 TargetCPUUtilizationPercentage: 90 TargetMemoryUtilizationPercentage: 80    Key Description     MaxReplicas Maximum number of replicas allowed for scaling.   MinReplicas Minimum number of replicas allowed for scaling.   TargetCPUUtilizationPercentage The target CPU utilization that is expected for a container.   TargetMemoryUtilizationPercentage The target memory utilization that is expected for a container.   enabled to enable autoscaling or don\u0026rsquo;t enable it.    Image image: pullPolicy: IfNotPresent Image is used to access images in kubernetes, pullpolicy is used to define the instances calling the image, here the image is pulled when the image is not present,it can also be set as \u0026ldquo;Always\u0026rdquo;.\nIngress This allows public access to the url, please ensure you are using right nginx annotation for nginx class, its default value is nginx\ningress: enabled: false annotations: {} path: \u0026#34;\u0026#34; host: \u0026#34;\u0026#34; tls: []    Key Description     enabled Enable or disable ingress   annotations To configure some options depending on the Ingress controller   path Path name   host Host name   tls It contains security details    Ingress Internal This allows private access to the url, please ensure you are using right nginx annotation for nginx class, its default value is nginx\ningressInternal: enabled: false annotations: {} path: \u0026#34;\u0026#34; host: \u0026#34;\u0026#34; tls: []    Key Description     enabled Enable or disable ingress   annotations To configure some options depending on the Ingress controller   path Path name   host Host name   tls It contains security details    Resources These define minimum and maximum RAM and CPU available to the application\nresources: limits: cpu: \u0026#39;1\u0026#39; memory: 200Mi requests: cpu: \u0026#39;0.10\u0026#39; memory: 100Mi Resources are required to set CPU and memory usage.\nLimits Limits make sure a container never goes above a certain value. The container is only allowed to go up to the limit, and then it is restricted.Requests Requests are what the container is guaranteed to get.\nService This defines annotations and the type of service, optionally can define name also\nservice: type: ClusterIP annotations: {} Volumes volumes: [] It is required when some values need to be read from or written to an external disk.\nVolume Mounts volumeMounts: [] It is used to provide mounts to the volume\nAffinity and anti-affinity Spec: Affinity: Key: Values: Spec is used to define the desire state of the given container.\nNode Affimity allows you to constrain which nodes your pod is eligible to schedule on, based on labels of the node.\nInter-pod affinity allow you to constrain which nodes your pod is eligible to be scheduled based on labels on pods.\nKey Key part of the label for node selection, this should be same as that on node. Please confirm with devops team\nValues Value part of the label for node selection, this should be same as that on node. Please confirm with devops team\nTolerations tolerations: key: \u0026#34;key\u0026#34; operator: \u0026#34;Equal\u0026#34; value: \u0026#34;value\u0026#34; effect: \u0026#34;NoSchedule|PreferNoSchedule|NoExecute(1.6 only)\u0026#34; Taints are the opposite, they allow a node to repel a set of pods.\nA given pod can access the given node and avoid the given taint only if the given pod satisfies a given taint.\nTaints and tolerations work together to ensure that pods are not scheduled onto the inappropriate nodes. One or more taints can be applied to a node, this marks that the node should not accept any pods that don\u0026rsquo;t tolerate the taints.\nArguments args: enabled: false value: [] This is used to give arguments to command\nCommand command: enabled: false value: [] It contains the commands for the server.\n   Key Description     enabled To enable or disable the command.   value It contains the commands.    Prometheus prometheus: release: monitoring It is a kubernetes monitoring tool and the name of the file to be monitored as monitoring in the given case.It describes the state of the prometheus.\nGrace Period GracePeriod: 30 If it has expired then the task is requeued to be executed again.\nMin Ready Seconds MinReadySeconds: 60 Minimum number of seconds for which a newly created pod should be ready without any of its container crashing, for it to be considered available\nServer server: deployment: image_tag: 1-95a53 image: \u0026#34;\u0026#34; It is used for providing server configurations.\nDeployment It gives the details for deployment\n   Key Description     image_tag It is the image tag   image It is the URL of the image    Service Monitor servicemonitor: enabled: true path: /abc scheme: \u0026#39;http\u0026#39; interval: 30s scrapeTimeout: 20s metricRelabelings: - sourceLabels: [namespace] regex: \u0026#39;(.*)\u0026#39; replacement: myapp targetLabel: target_namespace It gives the set of targets to be monitored.\nDb Migration Config dbMigrationConfig: enabled: false It is used to configure database migration\nApplication Metrics Application metrics can be enabled to see your application\u0026rsquo;s metrics-CPUService Monito usage,Memory Usage,Status,Throughput and Latency.\nDeployment Metrics A deployment strategy is a way to make changes to your application, without downtime in a way that your application user barely notices the changes. There are different types of deployment strategies. To know about Deployment Strategies, Click on: Types of Deployment Strategies\nAdd on features in Deployment Chart version 3.9.0 Service Account serviceAccountName: orchestrator A service account provides an identity for the processes that run in a Pod.\nWhen you access the cluster, you are authenticated by the apiserver as a particular User Account. Processes in containers inside pod can also contact the apiserver. When you are authenticated as a particular Service Account.\nWhen you create a pod, if you do not create a service account, it is automatically assigned the default service account in the namespace.\nPod Disruption Budget podDisruptionBudget: {} minAvailable: 1 maxUnavailable: 1 You can create PodDisruptionBudget for each application. A PDB limits the number of pods of a replicated application that are down simultaneously from voluntary disruptions. For example, an application would like to ensure the number of replicas running is never brought below the certain number.\nYou can specify maxUnavailable and minAvailable in a PodDisruptionBudget.\nWith minAvailable of 1, evictions are allowed as long as they leave behind 1 or more healthy pods of the total number of desired replicas.\nWith maxAvailable of 1, evictions are allowed as long as atmost 1 unhealthy replica among the total number of desired replicas.\nApplication metrics Envoy Configurations envoyproxy: image: envoyproxy/envoy:v1.14.1 configMapName: \u0026#34;\u0026#34; resources: limits: cpu: 50m memory: 50Mi requests: cpu: 50m memory: 50Mi Envoy is attached as a sidecar to the application container to collect metrics like 4XX, 5XX, Throughput and latency. You can now configure the envoy settings such as idleTimeout, resources etc.\nPrometheus Rule prometheusRule: enabled: true additionalLabels: {} namespace: \u0026#34;\u0026#34; rules: - alert: TooMany500s expr: 100 * ( sum( nginx_ingress_controller_requests{status=~\u0026#34;5.+\u0026#34;} ) / sum(nginx_ingress_controller_requests) ) \u0026gt; 5 for: 1m labels: severity: critical annotations: description: Too many 5XXs summary: More than 5% of the all requests did return 5XX, this require your attention Alerting rules allow you to define alert conditions based on Prometheus expressions and to send notifications about firing alerts to an external service.\nIn this case, Prometheus will check that the alert continues to be active during each evaluation for 1 minute before firing the alert. Elements that are active, but not firing yet, are in the pending state.\nCustom Metrics in HPA autoscaling: enabled: true MinReplicas: 1 MaxReplicas: 2 TargetCPUUtilizationPercentage: 90 TargetMemoryUtilizationPercentage: 80 HPA will be able to give metrics such as CPU and memory usage for cluster nodes or any of the pods. These metrics are useful for internal cluster sizing, but you probably want to configure wider set of metrics like service latency, I/O load etc.\nThe custom metrics in HPA can help you to achieve this.\n 3. Show application metrics  If you want to see application matrics like different status codes, application throughput, latency, response time. Enable the Show Application matrix from here. And you will get all metrics on App detail page. This is optional. You can leave it disabled. By default it remains disabled.\n    Once all the Deployment template configurations are done, click on Save to save your deployment configuration. Now you are ready to create Workflow to do CI/CD.\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/use_cases/connect_django_with_mysql_database/",
	"title": "Connect Django With Mysql Database",
	"tags": null,
	"description": "",
	"content": "Introduction Django is a free, open-source web framework written in Python programming language. It allows for scalability, re-usability, and rapid development. Django can be connected to different databases like MySQL, PostgreSQL, etc.\n1. Deploy a mysql Helm Chart To deploy mysql Helm Chart, you can refer to our documentation on Deploy mysql Helm Chart\n2. Fork the Git Repository For this example, we are using the following GitHub Repo, you can clone this repository and make following changes in the files.\n* Configure Database Settings Go to mysite/settings.py.\nThe settings.py contains the configuration for your SQL database. Make sure the configurations in settings.py matches the configurations of the mysql Helm Chart, that you have deployed in Step 1.\nDATABASES = { \u0026#39;default\u0026#39;: { # If you are using Cloud SQL for MySQL rather than PostgreSQL, set # \u0026#39;ENGINE\u0026#39;: \u0026#39;django.db.backends.mysql\u0026#39; instead of the following. \u0026#39;ENGINE\u0026#39;: \u0026#39;django.db.backends.postgresql\u0026#39;, \u0026#39;NAME\u0026#39;: \u0026#39;\u0026lt;mysql-database\u0026gt;\u0026#39;, \u0026#39;USER\u0026#39;: \u0026#39;\u0026lt;mysql-user\u0026gt;\u0026#39;, \u0026#39;PASSWORD\u0026#39;: \u0026#39;\u0026lt;mysql-password\u0026gt;\u0026#39;, \u0026#39;HOST\u0026#39;: \u0026#39;\u0026lt;service-name\u0026gt;\u0026#39;, \u0026#39;PORT\u0026#39;: \u0026#39;3306\u0026#39;, } }  3. Create Application on Devtron To learn how to create an application on Devtron, refer to our documentation on Creating Application\n* Git Material In this example, we are using the url of the forked Git Repository.\n* Docker configuration Give, the path of the Dockerfile.\n* Configure Deployment Template Enable Ingress, and give the path on which you want to host the application.\n  * Set up the CI/CD Pipelines Set up the CI/CD pipelines. You can set them to trigger automatically or manually.\n* Trigger Pipelines Trigger the CI Pipeline, build should be Successful, then trigger the CD Pipeline, deployment pipeline will be initiated, after some time the status should be Healthy.\n4. Final Step Check the Django app connected to mysql database, running successfully by hitting your application url.\nThe syntax is: http://\u0026lt;hostname\u0026gt;/\u0026lt;path\u0026gt;/\npath will be the one that you have given in Step 3 while configuring the Deployment Template.\n   "
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/deploy_chart/",
	"title": "Deploy Chart",
	"tags": null,
	"description": "",
	"content": "Welcome! This is the documentation for Deploying Charts.\nParts of Documentation\nOverview of Charts Examples\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/deploy_chart/examples/deploying_mongodb_helm_chart/",
	"title": "Deploying MongoDB Helm Chart",
	"tags": null,
	"description": "",
	"content": "Introduction Let\u0026rsquo;s assume that you are building an application which needs mongoDB.\n   Deploying applications as Helm Charts is the easiest way to create applications on Devtron.\nThis guide will introduce you to how to deploy the mongoDB\u0026rsquo;s Helm chart.\n1. Discover the Chart from the Chart Store Select the Charts section from the left pane, you will be landed to the Chart Store page. Click on Discover and find stable/mongodb-replicaset Helm Chart.\n    2. Configure the Chart After selecting the stable/mongodb helm chart, click on Deploy\n    Enter the following details, to deploy mongoDB chart:\n   Key Description     App Name Name of the Chart   Project Select the name of your Project in which you want to deploy the chart   Environment Select the environment in which you want to deploy the chart   Chart Version Select the latest Chart Version   Chart Value Select the latest default value or create a custom value    Configure values.yaml In this example replicas is set to 1 and persistenceVolume is set to false. You can configure it according to your project\u0026rsquo;s requirements.\nTo learn about different parameters used in the chart, you can check Documentation of mongodb Helm chart\n    Click on Deploy after you have finished configuring the chart.\n3. Check the Status of Deployment After clicking on Deploy you will land on a page, that shows the Status of the deployment of the Chart.\nThe Status of the chart should be Healthy. It might take few seconds after initiating the deployment of the chart.\n    In case the Status of the deployment is Degraded or takes a long time to get deployed.\nClick on the Status or check the logs of the pods to debug the issue.\n4. Extract the Service name Copy the service name, it will be used to connect your application to mongoDB .\n    "
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/creating_application/workflows/",
	"title": "Workflow",
	"tags": null,
	"description": "",
	"content": "Workflow is a logical sequenece of different stages used for continous integration and continous deployment of an application.\n  Click on Create Workflow to create a new workflow\n  Enter the name of your workflow and then Click on Add Workflow to add a new workflow.\nThen, Create CI/CD Pipelines for your application.\nTo know how to Create the CI Pipeline for your application Click On: Create CI Pipelines\nTo know how to Create the CD Pipeline for your application Click On: Create CD Pipelines\n "
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/debugging_deployments_and_monitoring/",
	"title": " Debugging Deployment And Monitoring",
	"tags": null,
	"description": "",
	"content": "Debugging Deployments If the deployment your application is not successful, then debugging needs to be done to check the cause of the error.\nThis can be done through App Details section which you can access in the following way:-\nApplications-\u0026gt;AppName-\u0026gt;App Details\nOver here, you can see the status of the app as Healthy. If there are some errors with deployment then the status would not be in a Healthy state.\nEvents     Events of the application are accessible from the bottom left corner.\nEvents section displays you the events that took place during the deployment of an app. These events are available until 15 minutes of deployment of the application.\nLogs     Logs contain the logs of the Pods and Containers deployed which you can use for the process of debugging.\nManifest     The Manifest shows the critical information such as Container-image, restartCount, state, phase, podIP, startTime etc. and status of the pods deployed.\nDeleting Pods     You might run into a situation where you need to delete Pods. You may need to bounce or restart a pod.\nDeleting a Pod is not an irksome task, it can simply be deleted by Clicking on Delete Pod.\nSuppose you want to setup a new environment, you can delete a pod and thereafter a new pod will be created automatically depending upon the replica count.\nApplication Objects You can view Application Objects in this section of App Details, such as:\n   Key Description     Workloads ReplicaSet(ensures how many replica of pod should be running), Status of Pod(status of the Pod)   Networking Service(an abstraction which defines a logical set of Pods), Endpoints(names of the endpoints that implement a Service), Ingress(API object that manages external access to the services in a cluster)   Config \u0026amp; Storage ConfigMap( API object used to store non-confidential data in key-value pairs)   Custom Resource Rollout(new Pods will be scheduled on Nodes with available resources), ServiceMonitor(specifies how groups of services should be monitored)        Monitoring     You can monitor the application in the App Detailssection.\nMetrics like CPU Usage, Memory Usage, Throughput and Latency can be viewed here.\n   Key Description     CPU Usage Percentage of CPU\u0026rsquo;s cycles used by the app.   Memory Usage Amount of memory used by app.   Throughput Performance of the app.   Latency Delay caused while transmitting the data.    "
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/creating_application/config_maps/",
	"title": "Config Maps",
	"tags": null,
	"description": "",
	"content": "The ConfigMap API resource holds key-value pairs of configuration data that can be consumed in pods or used to store configuration data for system components such as controllers. ConfigMap is similar to Secrets, but designed to more conveniently support working with strings that do not contain sensitive information.\nClick on Add ConfigMap to add a config map to your application.\n    Configure the ConfigMap        Key Description     Data Type(Kubernetes ConfigMap) ConfigMap that is created by Devtron.   Name Name of ConfigMap.   Environment Variable Select if there are Environment Variables to be injected in pods.   Data Volume Specify, if there is a volume that is accessible to Containers running in a pod needs to be added.   Key Key.   Value Value for a given key.    You can Click on \u0026ldquo;YAML\u0026rdquo; or \u0026ldquo;GUI\u0026rdquo; to view the key and Value parameters of the ConfigMap that you have created.\nVolume Mount Path Specify Volume Mount folder path in Volume Mount Path, path where the data volume needs to be mounted, which will be accessible to the Containers running in a pod.\nYou can Select the Data Type as Kubernetes ConfigMap if you wish to use the ConfigMap created by Devtron or Kubernetes External ConfigMap  if you have created a ConfigMap using Kubectl command.\n   Click Save ConfigMap to save the configMap.\nKubernetes External ConfigMap Kubernetes External ConfigMap is created using kubectl create configmap or you can use ConfigMap generator in kustomization.yaml to create a ConfigMap.\nIf you are using Kubernetes External ConfigMap make sure you give the name of ConfigMap same as the name that you have given using kubectl create Configmap \u0026lt;configmap-name\u0026gt; \u0026lt;data source\u0026gt; command, otherwise it might result in error during the built.\nYou have to ensure that the External ConfigMap exists and is made available to the pod.\n   The config map is created.\n "
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/namespaces_and_environments/",
	"title": "Namespaces And Environments",
	"tags": null,
	"description": "",
	"content": "Namespaces Kubernetes namespaces can be seen as a logical entity used to represent cluster resources for usage of a particular set of users. This logical entity can also be termed as a virtual cluster. One physical cluster can be represented as a set of multiple such virtual clusters (namespaces).\nMultiple Namespaces Namespaces are intended for use in environments with many users spread across multiple teams, or projects. Names of resources need to be unique within a namespace, but not across namespaces. Namespaces can not be nested inside one another and each Kubernetes resource can only be in one namespace\nEnvironments One of the advantages that Kubernetes provides is the ability to manage various environments easier and better than traditional deployment strategies. For most nontrivial applications, you have test, staging, and production environments. You can spin up a separate cluster of resources, such as VMs, with the same configuration in staging and production, but that can be costly and managing the differences between the environments can be difficult. Kubernetes includes a cool feature called namespaces, which enables you to manage different environments within the same cluster. For example, you can have different test and staging environments in the same cluster of machines, potentially saving resources.\nEnvironments in Devtron can be accessed from:-\nGlobal Configuration-\u0026gt;Clusters \u0026amp; Environments\n    Here multiple environments can be created\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/creating_application/secrets/",
	"title": "Secrets",
	"tags": null,
	"description": "",
	"content": "Secret objects lets you store and manage sensitive information, such as passwords, Auth tokens, and ssh keys. Embedding this information in a secret is safer and more flexible than putting it verbatim in a Pod definition or in a container image.\n   Click on Add Secret to add a new secret.\nConfigure Secret       Key Description     Name Name of the Secret   Data Type Data Type of the Secret, To know about different Data Types available Click on: Data Types   Data Volume Specify, if there is a volume that is accessible to Containers running in a pod needs to be added   Environment Variable Select if there are Environment Variables to be injected in pods   Key Key   Value Value for a given key    Data Types There are namely five Data types, that you can use to save your secret.\n  Kubernetes Secret : The secret that you create using Devtron.\n  Kubernetes External Secret : The secret data of your application is fetched externally, converts the Kubernetes External Secret to Kubernetes Secret. The conversion is completely transparent to Pods and secrets are accessed normally.\n  AWS Secret Manager : The secret data of your application is fetched from AWS Secret Manager, converts AWS Secret to Kubernetes Secret. The conversion is completely transparent to Pods that can access secrets normally.\n  AWS System Manager : The secret data for your application is fetched from AWS Secret Manager, converts the secrets stored in AWS System Manager to Kubernetes Secret. The conversion is completely transparent to Pods that can access secrets normally.\n  Harshi Corp Vault : The secret data for your application is fetched from AWS Secret Manager, converts the secrets stored in Harshi Corp Vault to Kubernetes Secret. The conversion is completely transparent to Pods that can access secrets normally.\n  Volume Mount Path Specify Volume Mount folder path in Volume Mount Path, path where the data volume needs to be mounted, which will be accessible to the Containers running in a pod.\n    Click on Save Secret to save the secret.\n   You can see the Secret is added.\n "
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/creating_application/environment_overrides/",
	"title": "Environment Overrides",
	"tags": null,
	"description": "",
	"content": "   You can customize the Deployment template in Environment Overrides section to customize things according to multiple environments such dev, test, integration, prod, etc.\nFor Example, You may have specified 100m CPU resource in the Deployment Template but in Production environment override you may want to have 500m CPU resource as the traffic on Pod is higher than usual.\nThe changed configuration will not be added in the template, instead it will make a copy of the template and lets you customize it and then save it. And now this overriden template will be used always for your Production Environment instead of the one specified in deployment template.\n "
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/security_features/",
	"title": "Security Features",
	"tags": null,
	"description": "",
	"content": " Devtron’s tool is also providing you Security Features to identify the vulnerabilities inside your code and to protect your code from external attacks.\nThe system will scan your code and inform you if there are any Vulnerabilities present in your code. Also to make this feature more flexible to use, we have added a capability using which you can whitelist or block any vulnerability, and your code will be scanned considering the defined whitelist or blocked vulnerabilities.\nRemember, we discussed the Scan for vulnerabilities option in the CI pipeline. You can enable this feature from the CI Pipeline page. The system will scan your code and will show you all vulnerabilities present in your code.\nWe have created Security features to identify the vulnerabilities inside your code and to protect you from external attacks.\nThis Security Feature has two processes:\n  Scanning\n  Policy\n  Scanning This process starts executing after the successful execution of the CI pipeline and before the deployment(CD) process starts.\nIt scans your code to find any potential threat and shows you the list of vulnerabilities as an output of the CI pipeline if it finds any.\nWe will discuss later how you will see the list of your found vulnerabilities.\n Policy Vulnerabilities have different levels like Critical, Moderate, and Low. Users can define Policy according to the level of vulnerability. Users can also block the vulnerability or allow(whitelist) the vulnerability for their code.\nIf any vulnerability is found which is blocked by the user, then it will not deploy the application. And if it finds any vulnerability which is whitelisted by the user, then the build image can be deployed.\nThe user gets informed in both cases if it finds any vulnerability or doesn\u0026rsquo;t find any.\n How to Check Vulnerability\nYou can find the Vulnerabilities Build History Page if you have enabled the Scan for vulnerabilities option.\n    Your Application-\u0026gt; Build History-\u0026gt; Select pipeline-\u0026gt; Go to Security Tab.\nHere you can see all the vulnerabilities found in the build image.\nEvery vulnerability has CVE ID, Severity Level, Package, Current Version, and Fixed In Version.\nCVE ID- Common vulnerability ID\nSeverity Level informs you about the severity of the vulnerability, it is defined as Critical, Medium, and Low.\nThe Package column contains some meta-data of vulnerability.\nThe Current Version is the version of that vulnerability\nFixed In Version column contains version name if it has been fixed in any version, else it remains blank\n Find Vulnerabilities on the Trigger Page\n You can find Vulnerabilities on the Trigger page also. Image having vulnerabilities will be marked as Security Issues Found and you won’t be able to select the image to deploy it.\nYou can see details of these vulnerabilities by expanding the Show Source Info.\nSee the below image.\n    Click on the Show Source Info option. A window will be expanded with two options- Changes and Security. Click on the Security tab to view details about the vulnerabilities in the code.\n   Find Vulnerabilities on the App Details Page\nYou can find Vulnerabilities on the App Details page too. Here we are displaying the total number of vulnerabilities found in the code and their Severity Level wise segregation.\n    Security You can check Vulnerabilities for all your applications in one place. On the Home page, there is an option named as Security. Here, you can see a list of applications under the Security Scan tab. Here all the applications are listed which have the Scan for Vulnerabilities feature enabled. You can see the vulnerability count along with the Severity Level for all your applications.\nNote:-\nIt displays the “Vulnerability count and Severity Level” on a priority basis. And critical level has the highest priority, so it displays the critical level vulnerabilities and there counts if any application is having critical Vulnerability in it.\nYou can directly Search your application using the Search bar or you can filter out your requirement according to Severity, Clusters, and Environment.\n    Now if you click on the severity level of vulnerability it will show you the list of all vulnerabilities along with other details.\n    Security Policies: Users can define Security policies for their vulnerabilities under Security Policies Tab.\nHome Page-\u0026gt; Security - \u0026gt; Security Policies\nPolicies can be defined to different levels-\n  Global\n  Cluster\n  Environment\n  Application\n  Note:-\nPolicies work in hierarchical order.\nOrder to be followed- First Global and second Cluster and so on as you can see the order of the options\n    Some examples of how policies can be defined\nUsers can block all the critical vulnerabilities and allow the moderate and low vulnerabilities or Users can block all vulnerabilities or users can block all vulnerabilities for one application and can block only Critical vulnerabilities for other applications.\nConfigure Global Policy To configure these policies, click on the drop-down option of the severity levels and select Block or Allow.\n    Configure Cluster Security Policy In the Global Security Policies, there are only two options available- Block and Allow. But in other options, we have an extra option named Inherit.\nAs the name itself gives you an idea about this option, it fetches the policy of its upper-level options, if we choose to inherit in the drop-down.\nExample-if you block critical severity levels in Global, then critical levels will be blocked in Cluster Security Policy. In case we change critical policy globally and allow it there, then it will be allowed in Cluster Security Policies too. But you can change these policies explicitly.\nIf you want to block Critical Vulnerabilities in Global Security Policies but want to allow them in some clusters, then select your cluster and change the critical drop-down to allow. It will not affect the policy of other clusters and global also.\nConfigure Environment Security Policy Again we have three options to define a policy- Block, Allow, and Inherit.\nEnvironment Security Policy inherits the policy from Cluster Security Policy. Each level inherits the policy of its upper level.\nSelect any environment here, you will find it is inheriting the policy of Cluster.\nExample- If you have blocked critical level vulnerabilities in Global Security Policy but allowed them in Cluster Security Policy, then Environment Security Policy will inherit the policy of cluster not global, Hence critical level vulnerabilities will be allowed in the Environment Security Policy.\nThough, You can change the policy explicitly.\nConfigure Application Security Policy The same thing goes with the Application Security Policy. But in Application, the policy is set with the combination of Environment option and Application option. If you change the policy in a dev environment that it will apply to all the applications which are in the dev environment.\nCheck CVE Policy Here is the last option Check CVE Policy, If you want to configure a security policy specific to any Vulnerability, you can use this option.\nClick on this option, it will show you a search bar, copy any CVE ID or vulnerability ID, and click on Search. It will display the details regarding that CVE ID and you can configure the policy to that particular CVE ID.\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/deleting_applications/",
	"title": "Deleting Application",
	"tags": null,
	"description": "",
	"content": "Delete the Application, when you are sure you no longer need it.\nClicking on Delete Application will not delete your application if you have workflows in the application.\nIf your Application contains workflows in the Workflow Editor. So,when you Click on Delete Application, you will see the following prompt.\n    Click on View Workflows to view and delete your workflows in the application.\nTo delete the workflows in your application, you must first delete all the pipelines(CD Pipeline, CI Pipeline or Linked CI Pipeline or External CI Pipeline if there are any).\n    After you have deleted all the pipelines in the workflow, you can delete that particular workflow.\nSimilarly, delete all the workflows in the application.\n    Now, Click on Delete Application to delete the application.\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/global_configurations/",
	"title": "Global Configurations",
	"tags": null,
	"description": "",
	"content": "This documentation consists of the Global Configurations available in Devtron.\nParts of the Documentation\nManage Notification\nUser Access\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/reference/use_cases/",
	"title": "Use Cases",
	"tags": null,
	"description": "",
	"content": "Welcome, this document consists of Devtron Use Cases\nRun Cron Jobs or One Time Job using Devtron Generic Helm Chart\n Connect SpringBoot with Mysql Database\n Connect Expressjs With Mongodb Database\n Connect Django With Mysql Database\n"
},
{
	"uri": "nivesh-goyal05.github.io/docs/hidden/",
	"title": "",
	"tags": null,
	"description": "",
	"content": ""
},
{
	"uri": "nivesh-goyal05.github.io/categories/",
	"title": "Categories",
	"tags": null,
	"description": "",
	"content": ""
},
{
	"uri": "nivesh-goyal05.github.io/",
	"title": "Introduction",
	"tags": null,
	"description": "",
	"content": "Devtron Documentation Continuous Deployment for Kubernetes that increases your productivity and reduces cost.\nBrowse Devtron Documentation\n"
},
{
	"uri": "nivesh-goyal05.github.io/tags/",
	"title": "Tags",
	"tags": null,
	"description": "",
	"content": ""
}]
